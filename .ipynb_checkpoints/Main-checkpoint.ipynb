{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib notebook\n",
    "# numpy, matplotlib, seaborn and matplotlib\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# missing data visualization library\n",
    "import missingno as msno\n",
    "sns.set_style('whitegrid')\n",
    "# define data path\n",
    "INPUT_PATH = \"../data/%s.csv\"\n",
    "# define small samples to quickly explore data\n",
    "read_rows = 300;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = pd.DataFrame(['NaN','NaN'],columns=['c1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Visualization Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview Part\n",
    "This part is to overview the first N rows of the sample to get initial feeling of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data head for overview\n",
    "train_date_overview = pd.read_csv('../data/train_date.csv',nrows = read_rows)\n",
    "train_categorical_overview = pd.read_csv('../data/train_categorical.csv',nrows = read_rows)\n",
    "train_numeric_overview = pd.read_csv('../data/train_numeric.csv',nrows = read_rows)\n",
    "#test_categorical_overview = pd.read_csv('../data/test_categorical.csv', nrows = read_rows)\n",
    "#test_date_overview = pd.read_csv('../data/test_date.csv', nrows = read_rows)\n",
    "#test_numeric_overview = pd.read_csv('../data/test_numeric.csv', nrows = read_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Start inspire missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_numeric_overview\n",
    "train_categorical_overview\n",
    "train_date_overview\n",
    "#test_numeric_overview\n",
    "#test_categorical_overview\n",
    "#test_date_overview "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Explore by value by station\n",
    "def explore_value_by_station(dataset, station_number,numeric = True):\n",
    "    if numeric:\n",
    "        columns_numeric = train_numeric_overview.columns.drop([\"Response\", \"Id\"])\n",
    "        stations_numeric = set([item.split('_')[1] for item in list(columns_numeric)])\n",
    "        station_numeric_features = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# explore by station\n",
    "columns_numeric = train_numeric_overview.columns.drop([\"Response\", \"Id\"])\n",
    "columns_categorial = train_categorical_overview.columns.drop([\"Id\"])\n",
    "columns_date = train_date_overview.columns.drop([\"Id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_numeric\n",
    "columns_categorial\n",
    "columns_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stations_numeric = set([item.split('_')[1] for item in list(columns_numeric)])\n",
    "stations_categorial = set([item.split('_')[1] for item in list(columns_categorial)])\n",
    "stations_date = set([item.split('_')[1] for item in list(columns_date)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(stations_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "station_numeric_features = {}\n",
    "stations_categorial_features = {}\n",
    "stations_date_features = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in stations_numeric:\n",
    "    station_numeric_features[s] = [item for item in list(columns_numeric) if '%s_' % s in item]\n",
    "# for s in stations_categorial:\n",
    "#     station_numeric_features[s] = [item for item in list(columns_categorial) if '%s_' % s in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "station_numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "station_numeric_features['S0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#seems missing value for all features in one station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_numeric_overview[station_numeric_features['S4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#wait for visualize the feature in station level\n",
    "# because nan comes with station level\n",
    "\n",
    "train_numeric_overview_explore_nan = pd.DataFrame(columns = stations_numeric) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_numeric_overview_explore_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_numeric_overview['S0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "station_numeric_features['S0'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_numeric_overview[station_numeric_features['S0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stations_numeric = list(stations_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stations_numeric = sorted(stations_numeric, key=lambda student: int(student[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stations_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in stations_numeric:\n",
    "   print( int(s[1]))\n",
    "   break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for s in stations_numeric:\n",
    "    train_numeric_overview_explore_nan[s] = train_numeric_overview[station_numeric_features[s][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(train_numeric_overview_explore_nan.columns, key=lambda student: int(student[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_numeric_overview_explore_nan =train_numeric_overview_explore_nan[sorted(train_numeric_overview_explore_nan.columns, key=lambda student: int(student[1:]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train_numeric_overview_explore_nan(,order())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "msno.matrix(train_numeric_overview_explore_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "msno.bar(train_numeric_overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Feature Exploration Part\n",
    "This part is to explore the common feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to calculate failure rate\n",
    "def get_failure_rate(file_name):\n",
    "    # will calculate the error rate from data on the file based on response col\n",
    "    # Respons: 1 = Failed QC , 0 = Passed QC\n",
    "    rows = pd.read_csv(INPUT_PATH % file_name, usecols=[\"Response\"])\n",
    "    failure_rate = rows[rows.Response == 1].size / float(rows[rows.Response == 0].size)\n",
    "    return failure_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to calculate data size in 6 dataset\n",
    "def explore_data_size():\n",
    "    # explore the size (rows, cols) of each file\n",
    "    data_files = ['train_numeric', 'train_date', 'train_categorical', 'test_numeric',\n",
    "                  'test_date', 'test_categorical']\n",
    "    stats = []\n",
    "    for file_name in data_files:\n",
    "        cols = pd.read_csv(INPUT_PATH % file_name, nrows=1)\n",
    "        rows = pd.read_csv(INPUT_PATH % file_name, usecols=[\"Id\"])\n",
    "        stats.append({'File': file_name, 'Rows': rows.shape[0], 'Columns': cols.shape[1]})\n",
    "    # convert the result into a DataFrame so we can do plotting.\n",
    "    df = pd.DataFrame(stats, columns=[\"File\", \"Rows\", \"Columns\"])\n",
    "    failure_rate = get_failure_rate('train_numeric')\n",
    "    df[\"Error\"] = 0\n",
    "    df.loc[df.File == 'train_numeric', 'Error'] = failure_rate\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get data size\n",
    "explore_data_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Numerical Feature Exploration Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_number_features(station_features):\n",
    "    total_features = 0\n",
    "    for key in station_features.keys():\n",
    "        total_features += len(station_features[key]) \n",
    "    return total_features\n",
    "\n",
    "def get_features(feature_list):\n",
    "    # function to group features by station or line of production the convention is:\n",
    "    # L1_S15_F232 means Line 1, Station 15, Feature 232\n",
    "    line_features = {}\n",
    "    station_features = {}\n",
    "    lines = set([item.split('_')[0] for item in feature_list])\n",
    "    stations = set([item.split('_')[1] for item in feature_list])\n",
    "\n",
    "    for l in lines:\n",
    "        line_features[l] = [item for item in feature_list if '%s_' % l in item]\n",
    "\n",
    "    for s in stations:\n",
    "        station_features[s] = [item for item in feature_list if '%s_' % s in item]\n",
    "    \n",
    "    print 'No. of lines: '+ str(len(lines))\n",
    "    print 'No. of stations: '+ str(len(stations))\n",
    "    print 'No. of features: '+ str(int(get_number_features(station_features)))\n",
    "    \n",
    "\n",
    "    return (line_features, station_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def explore_features(data_set_name,is_response):\n",
    "    # how many units processed in each station\n",
    "    # also percentage of failed/passed QS in each station\n",
    "    if is_response :\n",
    "        features = pd.read_csv(INPUT_PATH % data_set_name, nrows=1).drop([\"Response\", \"Id\"], axis=1).columns.values\n",
    "    else:\n",
    "        features = pd.read_csv(INPUT_PATH % data_set_name, nrows=1).drop([\"Id\"], axis=1).columns.values\n",
    "    \n",
    "    line_features, station_features = get_features(features)\n",
    "    # create a dataframe cols: station, features_count\n",
    "    sdf = pd.DataFrame(list({int(key[1:]): len(station_features[key]) for\n",
    "                             key in station_features.keys()}.items()),\n",
    "                       columns=[\"Station\", \"FeatureCount\"])\n",
    "    ldf = pd.DataFrame(list({int(key[1:]): len(line_features[key]) for\n",
    "                             key in line_features.keys()}.items()),\n",
    "                       columns=[\"Line\", \"FeatureCount\"])\n",
    "    \n",
    "    stations_plot = sdf.plot(x=\"Station\", y=\"FeatureCount\", kind=\"bar\",\n",
    "                             title=\"Fig.1 - Features by Station\",\n",
    "                             figsize=(13,6), fontsize=12)\n",
    "    \n",
    "    line_features_plot = ldf.plot(x=\"Line\",y=\"FeatureCount\", kind=\"bar\",\n",
    "                             title=\"Fig.2 - Features by line\",\n",
    "                             figsize=(13,6), fontsize=12)\n",
    "    \n",
    "    #print 'No. of features:'+ str(int(get_number_features(station_features)))\n",
    "    \n",
    "    return line_features, station_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lf, sf = explore_features(\"train_numeric\"\"train_numeric\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is to see how many parts per station, how many success and failure parts per station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def explore_product_by_station(data_set_name,read_rows):\n",
    "    # need to see how many product per station\n",
    "    # features = pd.read_csv(INPUT_PATH % data_set_name, nrows=1).drop([\"Response\", \"Id\"], axis=1).columns.values\n",
    "    # line_features, station_features = get_features(features)\n",
    "    station_features = sf\n",
    "    dwb_result = []\n",
    "    ppbs_result = []\n",
    "    rows = 0\n",
    "    # inside this loop we will try to calculate different data sets, this way we only read the\n",
    "    # files once since it takes a while and produce multiple results\n",
    "    for station in station_features:\n",
    "        station_data = pd.read_csv(\n",
    "            INPUT_PATH % data_set_name,\n",
    "            usecols=station_features[station] + ['Id', 'Response'],nrows = read_rows)\n",
    "        \n",
    "        # need to get how many rows in the sample row\n",
    "        if not rows:\n",
    "            rows = station_data.shape[0]\n",
    "        # need to store how many processed units in each station\n",
    "        # only if all features in that station has value we conside unit processed in this station\n",
    "        ppbs_result.append(\n",
    "            {'Station': int(station[1:]),\n",
    "             'Processed': station_data[station_features[station]].notnull().all(axis=1).sum()})\n",
    "        \n",
    "        # data without blanks (dwb): take all rows and drop any row that has any blank\n",
    "        # in any station column\n",
    "        dwb = station_data.dropna(how=\"any\")\n",
    "        dwb_result.append([int(station[1:]), dwb.shape[0],\n",
    "                       dwb[dwb[\"Response\"] == 1].shape[0],\n",
    "                       dwb[dwb[\"Response\"] == 0].shape[0]])\n",
    "        \n",
    "    # convert list to a dataframe and prepare for the plot\n",
    "    dwb_df = pd.DataFrame(\n",
    "        dwb_result, columns=[\"Station\", \"Count\", \"Failed\", \"Passed\"]).sort_values(by=[\"Station\"])\n",
    "    # calculate the error rate for each station\n",
    "    dwb_df[\"Error\"] = dwb_df.apply(lambda row: float(row[\"Failed\"]) / (row[\"Count\"] + 1), axis=1)\n",
    "    \n",
    "    # plot the stacked bar tot product/ station\n",
    "    my_plot = dwb_df[[\"Station\", \"Failed\", \"Passed\"]].plot(kind=\"bar\", stacked=True, x=\"Station\",\n",
    "        title=\"Fig:3 - Products by station\", figsize=(13,6), fontsize=12)\n",
    "    my_plot.set_xlabel(\"Stations\")\n",
    "    my_plot.set_ylabel(\"Record Count\")\n",
    "    \n",
    "    # plot error rate per station\n",
    "    my_plot = dwb_df[[\"Station\", \"Error\"]].plot(\n",
    "        kind=\"bar\", x=\"Station\",\n",
    "        title=\"Fig:4 - Error by station\", figsize=(13,6), fontsize=12)\n",
    "    my_plot.set_xlabel(\"Stations\")\n",
    "    my_plot.set_ylabel(\"Error %\")\n",
    "    \n",
    "    # process the ppbs result to see how many products has been process by each station.\n",
    "    ppbs_df = pd.DataFrame(\n",
    "        ppbs_result, columns=['Station', 'Processed']).sort(columns=['Station'])\n",
    "    # calculate the missed product for each station: all count - processed count\n",
    "    ppbs_df[\"Missed\"] = ppbs_df[\"Processed\"].apply(lambda x: rows - x)\n",
    "    # the plot\n",
    "    ppbs_df.plot(x=\"Station\", kind=\"bar\", stacked=True,\n",
    "            title=\"Fig: 5 - Products processed by each station\",\n",
    "            figsize=(13,6), fontsize=12)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explore_product_by_station(\"train_numeric\",300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Value exploration by station part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def over_view_by_station(dataset, station_number):\n",
    "    train_overview = pd.read_csv(INPUT_PATH % dataset,nrows = read_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# overview again to compare with latter results\n",
    "train_overview = pd.read_csv(INPUT_PATH % 'train_numeric',nrows = read_rows)\n",
    "train_overview.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# overview again with respect to a station\n",
    "def overview_station(dataset, station, res = False):\n",
    "    train_overview = pd.read_csv(INPUT_PATH % dataset,nrows = read_rows)\n",
    "    if res:\n",
    "        columns = train_overview.columns.drop([\"Response\", \"Id\"])\n",
    "    else:\n",
    "        columns = train_overview.columns.drop([\"Id\"])\n",
    "        \n",
    "    stations = set([item.split('_')[1] for item in list(columns)])\n",
    "    station_features = {}\n",
    "    for s in stations_numeric:\n",
    "        station_features[s] = [item for item in list(columns) if '%s_' % s in item]  \n",
    "    station_features[station]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Categorial Data Exploration Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lf, sf = explore_features(\"train_categorical\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this function is to explore sparsity rate per row\n",
    "def explore_sparse_rate(data_set_name, read_rows):\n",
    "    train_categorical = pd.read_csv(INPUT_PATH % data_set_name,nrows = read_rows).drop([\"Id\"], axis=1)\n",
    "    sparse_rate_each_part = []\n",
    "    sparse_rate_series = train_categorical.isnull().sum(axis = 1)/train_categorical.shape[1]\n",
    "    sparse_rate_df = pd.DataFrame(\n",
    "        sparse_rate_series, columns=['sparse_rate'])\n",
    "    return sparse_rate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "explore_sparse_rate('train_categorical', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function is to get feeling of the TX value in the dataset\n",
    "def explore_dintinct_Tx_value(data_set_name, read_rows):\n",
    "    train_categorical = pd.read_csv(INPUT_PATH % 'train_categorical',nrows = read_rows)\n",
    "    del train_categorical['Id']\n",
    "    train_categorical_zeroes = train_categorical.fillna(0)\n",
    "    train_categorical_zeroes = train_categorical_zeroes.values \n",
    "    return np.unique(train_categorical_zeroes[train_categorical_zeroes!=0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "explore_dintinct_Tx_value('train_categorical', 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Enginnering Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Method 1 : Applying PCA for Dimension Reduction\n",
    "Preliminary work to search for appropriate n component\n",
    "benchmark: how many variance is explained or we maintain how much variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import additional pakage\n",
    "import math\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn import preprocessing\n",
    "# define chunksize how many rows load one time\n",
    "chunksize  = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Getting the column headers from first rows\n",
    "# Reading as float32 to save Memory \n",
    "data = pd.read_csv(INPUT_PATH % 'train_numeric',nrows=1)\n",
    "float_cols = [c for c in data]\n",
    "float32_cols = {c: np.float32 for c in float_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the number of pc for preliminary decomposition\n",
    "n_components = 968\n",
    "predictors = [x for x in data.keys() if (x != 'Response' and x != 'Id')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standard_feature_scaling(df):\n",
    "    std_scale = preprocessing.StandardScaler().fit(df)\n",
    "    df_std = pd.DataFrame(std_scale.transform(df))\n",
    "    df_std.columns = df.columns\n",
    "    df_std.index = df.index\n",
    "    return df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mean_imputer(DF):\n",
    "    fill_NaN = preprocessing.Imputer(missing_values=np.nan, strategy='mean')\n",
    "    imputed_DF = pd.DataFrame(fill_NaN.fit_transform(DF))\n",
    "    imputed_DF.columns = DF.columns\n",
    "    imputed_DF.index = DF.index\n",
    "    return imputed_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ipca = IncrementalPCA(n_components=968)\n",
    "# Due to the large dataset read data seperately in chunks and perform IncrementalPCA \n",
    "counter = 0\n",
    "for chunk in pd.read_csv(INPUT_PATH % 'train_numeric', chunksize=chunksize,dtype=float32_cols):\n",
    "    counter += chunksize\n",
    "    print ('processed',counter,'samples')\n",
    "# To do: what value to fill NA \n",
    "    imputed_chunk = chunk[predictors].fillna(0.09)\n",
    "    #imputed_chunk = mean_imputer(chunk[predictors])\n",
    "    scailed_chunk = standard_feature_scaling(imputed_chunk)\n",
    "#    chunk  = scailed_chunk.fillna(0)\n",
    "    ipca.partial_fit(scailed_chunk)\n",
    "print ('Number of Samples Seen:',ipca.n_samples_seen_ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_explained_variance(pca_components):\n",
    "    #print ('Explained variance by %d PCs:' %pca_components, np.sum(ipca.explained_variance_ratio_[:pca_components]))\n",
    "    return np.sum(ipca.explained_variance_ratio_[:pca_components])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot how many variance is explained based on how many n_components\n",
    "n_components_value = range(968)\n",
    "n_components_explained_variance = [get_explained_variance(x) for x in n_components_value]\n",
    "explained_variance_pd = pd.DataFrame(n_components_explained_variance, columns=['explained_variance_rate'])\n",
    "my_plot = explained_variance_pd.plot(title=\"explained_variance_rate\", figsize=(10,6), fontsize=12)\n",
    "my_plot.set_ylabel(\"Explained Variance Rate\")\n",
    "my_plot.set_xlabel(\"Number of Component\")\n",
    "n_components_explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make Train DataFrame only with n PC \n",
    "PC_n = ['f'+str(x) for x in range(0,n_components)]\n",
    "date_final = pd.DataFrame(columns=PC_n)\n",
    "for cat in pd.read_csv(INPUT_PATH % 'train_numeric', chunksize=chunksize,dtype=float32_cols):\n",
    "        cat  = cat.fillna(999)\n",
    "        y=ipca.transform(cat[predictors])\n",
    "        temp = cat['Id'].to_frame()\n",
    "        for i in PC_n:\n",
    "            temp[i]=0\n",
    "        temp[PC_n]=y\n",
    "        date_final = date_final.merge(temp, how='outer')\n",
    "print (date_final)\n",
    "date_final['Id'] = date_final['Id'].astype(np.int32)\n",
    "# save new dataset to CSV file \n",
    "train_filename = 'train_numeric_SVD_%s.csv' % n_components\n",
    "#date_final.to_csv(INPUT_PATH % train_filename,index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make Test DataFrame only with n PC \n",
    "PC_n = ['f'+str(x) for x in range(0,n_components)]\n",
    "date_final = pd.DataFrame(columns=PC_n)\n",
    "for cat in pd.read_csv('../input/test_numeric.csv', chunksize=chunksize,dtype=float32_cols):\n",
    "        cat  = cat.fillna(999)\n",
    "        y=ipca.transform(cat[predictors])\n",
    "        temp = cat['Id'].to_frame()\n",
    "        for i in PC_n:\n",
    "            temp[i]=0\n",
    "        temp[PC_n]=y\n",
    "        date_final = date_final.merge(temp, how='outer')\n",
    "date_final['Id'] = date_final['Id'].astype(np.int32)\n",
    "test_filename = 'test_numeric_SVD_%s.csv' % n_components\n",
    "# Save dataset to CSV file\n",
    "#date_final.to_csv(INPUT_PATH % test_filename,index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2 : XGBoost to select important features\n",
    "\n",
    "choose 25 top date and numerical features reported by initial xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import additional package\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import matthews_corrcoef, roc_auc_score\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sample the data in a roundabout way to get 5 percent sample\n",
    "date_chunks = pd.read_csv(\"../data/train_date.csv\", index_col=0, chunksize=10000, dtype=np.float32)\n",
    "num_chunks = pd.read_csv(\"../data/train_numeric.csv\", index_col=0,\n",
    "                         usecols=list(range(969)), chunksize=10000, dtype=np.float32)\n",
    "df_train = pd.concat([pd.concat([dchunk, nchunk], axis=1).sample(frac=0.05)\n",
    "               for dchunk, nchunk in zip(date_chunks, num_chunks)])\n",
    "y_sample = pd.read_csv(\"../data/train_numeric.csv\", index_col=0, usecols=[0,969], dtype=np.float32).loc[df_train.index].values.ravel()\n",
    "x_sample = df_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # now just numerical feature to see the result\n",
    "# num_chunks = pd.read_csv(\"../data/train_numeric.csv\", index_col=0,\n",
    "#                          usecols=list(range(969)), chunksize=10000, dtype=np.float32)\n",
    "# df_train = pd.concat([nchunk for nchunk in num_chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO fit y ravel or not?\n",
    "clf = XGBClassifier(base_score=0.005)\n",
    "clf.fit(x_sample, y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fea_importance = pd.DataFrame(clf.feature_importances_)\n",
    "fea_importance.index = df_train.columns\n",
    "fea_importance.columns=[\"feature_importance\"]\n",
    "# select 25 most important feature for xgboost\n",
    "fea_importance_sorted = fea_importance.sort(['feature_importance'], ascending=[0])\n",
    "important_feature_num_date = fea_importance_sorted.ix[0:25,0]\n",
    "important_feature_num_date.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_feature_value = pd.read_csv(INPUT_PATH % 'train_date',nrows=1).columns.drop(['Id']).values.tolist()\n",
    "important_feature_num_list = list(set(important_feature_num_date.index.values.tolist())-set(date_feature_value))\n",
    "important_feature_date_list = list(set(important_feature_num_date.index.values.tolist())-set(important_feature_num_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load entire dataset for these features. \n",
    "X = np.concatenate([\n",
    "    pd.read_csv(\"../data/train_date.csv\", index_col=0, dtype=np.float32,\n",
    "                usecols=['Id']+important_feature_date_list).values,\n",
    "    pd.read_csv(\"../data/train_numeric.csv\", index_col=0, dtype=np.float32,\n",
    "                usecols=['Id']+important_feature_num_list).values\n",
    "], axis=1)\n",
    "\n",
    "y = pd.read_csv(\"../data/train_numeric.csv\", index_col=0, dtype=np.float32, usecols=[0,969]).values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create important feature dataframe and plot\n",
    "# fea_importance = pd.DataFrame(clf.feature_importances_)\n",
    "# fea_importance.index = df_train.columns\n",
    "# fea_importance.columns=[\"feature_importance\"]\n",
    "\n",
    "# fea_importance_new = fea_importance[fea_importance.feature_importance >0.005]\n",
    "# fea_importance_new.plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# threshold for a manageable number of features\n",
    "# plt.hist(clf.feature_importances_[clf.feature_importances_>0])\n",
    "# important_indices = np.where(clf.feature_importances_>0.005)[0]\n",
    "# print(important_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load entire dataset for these features. \n",
    "# note where the feature indices are split so we can load the correct ones straight from read_csv\n",
    "# n_date_features = 1156\n",
    "# X = np.concatenate([\n",
    "#     pd.read_csv(\"../data/train_date.csv\", index_col=0, dtype=np.float32,\n",
    "#                 usecols=np.concatenate([[0], important_indices[important_indices < n_date_features] + 1])).values,\n",
    "#     pd.read_csv(\"../data/train_numeric.csv\", index_col=0, dtype=np.float32,\n",
    "#                 usecols=np.concatenate([[0], important_indices[important_indices >= n_date_features] + 1 - n_date_features])).values\n",
    "# ], axis=1)\n",
    "\n",
    "# y = pd.read_csv(\"../data/train_numeric.csv\", index_col=0, dtype=np.float32, usecols=[0,969]).values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3 : Magic Feature \n",
    "Start time.   Component(part) production start time\n",
    "\n",
    "MF1.  difference of Id between current and previous rows \n",
    "\n",
    "MF2.  difference of Id between current and next rows \n",
    "\n",
    "MF3.  difference of Id between current and previous rows after sorting on increasing StartTime and Id\n",
    "\n",
    "\n",
    "MF4.  difference of Id between current and next rows after sorting on increasing StartTime and Id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ID_COLUMN = 'Id'\n",
    "TARGET_COLUMN = 'Response'\n",
    "train = pd.read_csv(INPUT_PATH %'train_numeric', usecols=[ID_COLUMN, TARGET_COLUMN])\n",
    "\n",
    "test = pd.read_csv(INPUT_PATH %'test_numeric', usecols=[ID_COLUMN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start Time feature\n",
    "train[\"StartTime\"] = -1\n",
    "test[\"StartTime\"] = -1\n",
    "# Duration time feature\n",
    "train[\"Duration\"] = -1\n",
    "test[\"Duration\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill in start time\n",
    "for tr, te in zip(pd.read_csv(INPUT_PATH %'train_date', chunksize=50000), pd.read_csv(INPUT_PATH %'test_date', chunksize=50000)):\n",
    "    #pick all columns except ID\n",
    "    feats = np.setdiff1d(tr.columns, [ID_COLUMN])\n",
    "\n",
    "    stime_tr = tr[feats].min(axis=1).values\n",
    "    stime_te = te[feats].min(axis=1).values\n",
    "    \n",
    "    etime_tr = tr[feats].max(axis=1).values\n",
    "    etime_te = te[feats].max(axis=1).values\n",
    "\n",
    "    train.loc[train.Id.isin(tr.Id), 'StartTime'] = stime_tr\n",
    "    test.loc[test.Id.isin(te.Id), 'StartTime'] = stime_te\n",
    "    \n",
    "    train.loc[train.Id.isin(tr.Id), 'Duration'] = etime_tr - stime_tr\n",
    "    test.loc[test.Id.isin(te.Id), 'Duration'] = etime_te - stime_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ntrain = train.shape[0]\n",
    "train_test = pd.concat((train, test)).reset_index(drop=True).reset_index(drop=False)\n",
    "# Begin to create MF1 & MF2\n",
    "train_test['MF1'] = train_test[ID_COLUMN].diff().fillna(9999999).astype(int)\n",
    "train_test['MF2'] = train_test[ID_COLUMN].iloc[::-1].diff().fillna(9999999).astype(int)\n",
    "\n",
    "train_test = train_test.sort_values(by=['StartTime', 'Id'], ascending=True)\n",
    "# Begin to create MF3 & MF4\n",
    "train_test['MF3'] = train_test[ID_COLUMN].diff().fillna(9999999).astype(int)\n",
    "train_test['MF4'] = train_test[ID_COLUMN].iloc[::-1].diff().fillna(9999999).astype(int)\n",
    "\n",
    "train_test = train_test.sort_values(by=['index']).drop(['index'], axis=1)\n",
    "train = train_test.iloc[:ntrain, :]\n",
    "test = train_test.iloc[ntrain:, :]\n",
    "\n",
    "features = np.setdiff1d(list(train.columns), [TARGET_COLUMN, ID_COLUMN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_magic_feature_train = train[features]\n",
    "df_magic_feature_test = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_magic_feature_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ntrain = train.shape[0]\n",
    "# train_test = pd.concat((train, test)).reset_index(drop=True).reset_index(drop=False)\n",
    "# # Begin to create MF1 & MF2\n",
    "# train_test['MF1'] = train_test[ID_COLUMN].diff().fillna(9999999).astype(int)\n",
    "# train_test['MF2'] = train_test[ID_COLUMN].iloc[::-1].diff().fillna(9999999).astype(int)\n",
    "\n",
    "# train_test = train_test.sort_values(by=['StartTime', 'Id'], ascending=True)\n",
    "# # Begin to create MF3 & MF4\n",
    "# train_test['MF3'] = train_test[ID_COLUMN].diff().fillna(9999999).astype(int)\n",
    "# train_test['MF4'] = train_test[ID_COLUMN].iloc[::-1].diff().fillna(9999999).astype(int)\n",
    "\n",
    "# train_test = train_test.sort_values(by=['index']).drop(['index'], axis=1)\n",
    "# train = train_test.iloc[:ntrain, :]\n",
    "\n",
    "# features = np.setdiff1d(list(train.columns), [TARGET_COLUMN, ID_COLUMN])\n",
    "\n",
    "# y = train.Response.ravel()\n",
    "# train = np.array(train[features])\n",
    "\n",
    "# print('train: {0}'.format(train.shape))\n",
    "# prior = np.sum(y) / (1.*len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all features and Finish feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_feature will be the ensembled feature afterwards\n",
    "train_feature = pd.DataFrame(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put important feature in the dataframe \n",
    "train_feature.columns = important_feature_num_date.index\n",
    "train_feature = pd.concat([train_feature,df_magic_feature_train],axis=1)\n",
    "#end of feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 : XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# self-defined xgb model wrapper including data processing, model fit, predict and result \n",
    "def modelfit(alg, dtrain, labels,useTrainCV=True, model_fit=True,model_predict=True,cv_folds=5, early_stopping_rounds=20):\n",
    "    # trainCV with early stop so we don't need to use sciki-learn GridsearchCV , the later can't run in my computer\n",
    "    best_threshold = 0.5\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain.values, label=labels)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    if model_fit:\n",
    "        #Fit the algorithm on the data\n",
    "        alg.fit(dtrain.values, labels, eval_metric='auc')\n",
    "        print (\"fit done\")\n",
    "    if model_predict:\n",
    "    #Predict training set:\n",
    "        dtrain_predprob = alg.predict_proba(dtrain.values)[:,1]\n",
    "        thresholds = np.linspace(0.01, 0.99, 50)\n",
    "        mcc = np.array([matthews_corrcoef(labels, dtrain_predprob>thr) for thr in thresholds])    \n",
    "        fig2 = plt.figure(2)\n",
    "        plt.plot(thresholds, mcc)\n",
    "        best_threshold = thresholds[mcc.argmax()]\n",
    "        print('MCC is' + str(mcc.max()))\n",
    "        print('best threshold is'+ str(best_threshold))\n",
    "    return best_threshold\n",
    "    #Print model report:\n",
    "#     print (\"\\nModel Report\")\n",
    "#     print (\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain[target].values, dtrain_predictions))\n",
    "#     print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain[target], dtrain_predprob))\n",
    "                    \n",
    "#     feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "#     feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "#     plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Hyper-Parameter Tuning Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this part is for hyper-parameter tuning, but limited by my computer, \n",
    "# I can't run out of the result with gridsearchCV so instead i'm using cv\n",
    "# provided by xgboost\n",
    "\n",
    "# tunning 1 \n",
    "# max_depth and min_child_weight\n",
    "\n",
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=10, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(train_feature,y)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Training and Cross Validation Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb_starter = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=10,\n",
    " max_depth=10,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.7,\n",
    " colsample_bytree=0.7,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=0,\n",
    " base_score=0.005)\n",
    "\n",
    "best_threshold = modelfit(xgb_starter, train_feature, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load test data, predict labels and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "important_feature_date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load test data\n",
    "test_feature = np.concatenate([\n",
    "    pd.read_csv(\"../data/test_date.csv\", index_col=0, dtype=np.float32,\n",
    "                usecols=['Id']+important_feature_date_list).values,\n",
    "    pd.read_csv(\"../data/test_numeric.csv\", index_col=0, dtype=np.float32,\n",
    "                usecols=['Id']+important_feature_num_list).values,\n",
    "], axis=1)\n",
    "test_feature = np.concatenate([test_feature,df_magic_feature_test.values],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate predictions at the chosen threshold\n",
    "preds = (xgb_starter.predict_proba(test_feature)[:,1] > best_threshold).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# and submit\n",
    "sub = pd.read_csv(\"../data/sample_submission.csv\", index_col=0)\n",
    "sub[\"Response\"] = preds\n",
    "sub.to_csv(\"submission.csv.gz\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
