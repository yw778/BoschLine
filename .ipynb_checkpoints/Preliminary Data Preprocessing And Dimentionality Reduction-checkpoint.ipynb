{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib notebook\n",
    "# numpy, matplotlib, seaborn and matplotlib\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "# define data path\n",
    "INPUT_PATH = \"../data/%s.csv\"\n",
    "# define small samples to quickly explore data\n",
    "read_rows = 300;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Visualization Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview Part\n",
    "This part is to overview the first N rows of the sample to get initial feeling of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data head for overview\n",
    "train_date_overview = pd.read_csv('../data/train_date.csv',nrows = read_rows)\n",
    "train_categorical_overview = pd.read_csv('../data/train_categorical.csv',nrows = read_rows)\n",
    "train_numeric_overview = pd.read_csv('../data/train_numeric.csv',nrows = read_rows)\n",
    "test_categorical_overview = pd.read_csv('../data/test_categorical.csv', nrows = read_rows)\n",
    "test_date_overview = pd.read_csv('../data/test_date.csv', nrows = read_rows)\n",
    "test_numeric_overview = pd.read_csv('../data/test_numeric.csv', nrows = read_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_numeric_overview\n",
    "#train_categorical_overview\n",
    "train_date_overview\n",
    "#test_numeric_overview\n",
    "#test_categorical_overview\n",
    "test_date_overview "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Feature Exploration Part\n",
    "This part is to explore the common feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to calculate failure rate\n",
    "def get_failure_rate(file_name):\n",
    "    # will calculate the error rate from data on the file based on response col\n",
    "    # Respons: 1 = Failed QC , 0 = Passed QC\n",
    "    rows = pd.read_csv(INPUT_PATH % file_name, usecols=[\"Response\"])\n",
    "    failure_rate = rows[rows.Response == 1].size / float(rows[rows.Response == 0].size)\n",
    "    return failure_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to calculate data size in 6 dataset\n",
    "def explore_data_size():\n",
    "    # explore the size (rows, cols) of each file\n",
    "    data_files = ['train_numeric', 'train_date', 'train_categorical', 'test_numeric',\n",
    "                  'test_date', 'test_categorical']\n",
    "    stats = []\n",
    "    for file_name in data_files:\n",
    "        cols = pd.read_csv(INPUT_PATH % file_name, nrows=1)\n",
    "        rows = pd.read_csv(INPUT_PATH % file_name, usecols=[\"Id\"])\n",
    "        stats.append({'File': file_name, 'Rows': rows.shape[0], 'Columns': cols.shape[1]})\n",
    "    # convert the result into a DataFrame so we can do plotting.\n",
    "    df = pd.DataFrame(stats, columns=[\"File\", \"Rows\", \"Columns\"])\n",
    "    failure_rate = get_failure_rate('train_numeric')\n",
    "    df[\"Error\"] = 0\n",
    "    df.loc[df.File == 'train_numeric', 'Error'] = failure_rate\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get data size\n",
    "explore_data_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Numerical Feature Exploration Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_number_features(station_features):\n",
    "    total_features = 0\n",
    "    for key in station_features.keys():\n",
    "        total_features += len(station_features[key]) \n",
    "    return total_features\n",
    "\n",
    "def get_features(feature_list):\n",
    "    # function to group features by station or line of production the convention is:\n",
    "    # L1_S15_F232 means Line 1, Station 15, Feature 232\n",
    "    line_features = {}\n",
    "    station_features = {}\n",
    "    lines = set([item.split('_')[0] for item in feature_list])\n",
    "    stations = set([item.split('_')[1] for item in feature_list])\n",
    "\n",
    "    for l in lines:\n",
    "        line_features[l] = [item for item in feature_list if '%s_' % l in item]\n",
    "\n",
    "    for s in stations:\n",
    "        station_features[s] = [item for item in feature_list if '%s_' % s in item]\n",
    "    \n",
    "    print 'No. of lines: '+ str(len(lines))\n",
    "    print 'No. of stations: '+ str(len(stations))\n",
    "    print 'No. of features: '+ str(int(get_number_features(station_features)))\n",
    "    \n",
    "\n",
    "    return (line_features, station_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def explore_features(data_set_name,is_response):\n",
    "    # how many units processed in each station\n",
    "    # also percentage of failed/passed QS in each station\n",
    "    if is_response :\n",
    "        features = pd.read_csv(INPUT_PATH % data_set_name, nrows=1).drop([\"Response\", \"Id\"], axis=1).columns.values\n",
    "    else:\n",
    "        features = pd.read_csv(INPUT_PATH % data_set_name, nrows=1).drop([\"Id\"], axis=1).columns.values\n",
    "    \n",
    "    line_features, station_features = get_features(features)\n",
    "    # create a dataframe cols: station, features_count\n",
    "    sdf = pd.DataFrame(list({int(key[1:]): len(station_features[key]) for\n",
    "                             key in station_features.keys()}.items()),\n",
    "                       columns=[\"Station\", \"FeatureCount\"])\n",
    "    ldf = pd.DataFrame(list({int(key[1:]): len(line_features[key]) for\n",
    "                             key in line_features.keys()}.items()),\n",
    "                       columns=[\"Line\", \"FeatureCount\"])\n",
    "    \n",
    "    stations_plot = sdf.plot(x=\"Station\", y=\"FeatureCount\", kind=\"bar\",\n",
    "                             title=\"Fig.1 - Features by Station\",\n",
    "                             figsize=(13,6), fontsize=12)\n",
    "    \n",
    "    line_features_plot = ldf.plot(x=\"Line\",y=\"FeatureCount\", kind=\"bar\",\n",
    "                             title=\"Fig.2 - Features by line\",\n",
    "                             figsize=(13,6), fontsize=12)\n",
    "    \n",
    "    #print 'No. of features:'+ str(int(get_number_features(station_features)))\n",
    "    \n",
    "    return line_features, station_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lf, sf = explore_features(\"train_numeric\"\"train_numeric\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is to see how many parts per station, how many success and failure parts per station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def explore_product_by_station(data_set_name,read_rows):\n",
    "    # need to see how many product per station\n",
    "    # features = pd.read_csv(INPUT_PATH % data_set_name, nrows=1).drop([\"Response\", \"Id\"], axis=1).columns.values\n",
    "    # line_features, station_features = get_features(features)\n",
    "    station_features = sf\n",
    "    dwb_result = []\n",
    "    ppbs_result = []\n",
    "    rows = 0\n",
    "    # inside this loop we will try to calculate different data sets, this way we only read the\n",
    "    # files once since it takes a while and produce multiple results\n",
    "    for station in station_features:\n",
    "        station_data = pd.read_csv(\n",
    "            INPUT_PATH % data_set_name,\n",
    "            usecols=station_features[station] + ['Id', 'Response'],nrows = read_rows)\n",
    "        \n",
    "        # need to get how many rows in the sample row\n",
    "        if not rows:\n",
    "            rows = station_data.shape[0]\n",
    "        # need to store how many processed units in each station\n",
    "        # only if all features in that station has value we conside unit processed in this station\n",
    "        ppbs_result.append(\n",
    "            {'Station': int(station[1:]),\n",
    "             'Processed': station_data[station_features[station]].notnull().all(axis=1).sum()})\n",
    "        \n",
    "        # data without blanks (dwb): take all rows and drop any row that has any blank\n",
    "        # in any station column\n",
    "        dwb = station_data.dropna(how=\"any\")\n",
    "        dwb_result.append([int(station[1:]), dwb.shape[0],\n",
    "                       dwb[dwb[\"Response\"] == 1].shape[0],\n",
    "                       dwb[dwb[\"Response\"] == 0].shape[0]])\n",
    "        \n",
    "    # convert list to a dataframe and prepare for the plot\n",
    "    dwb_df = pd.DataFrame(\n",
    "        dwb_result, columns=[\"Station\", \"Count\", \"Failed\", \"Passed\"]).sort_values(by=[\"Station\"])\n",
    "    # calculate the error rate for each station\n",
    "    dwb_df[\"Error\"] = dwb_df.apply(lambda row: float(row[\"Failed\"]) / (row[\"Count\"] + 1), axis=1)\n",
    "    \n",
    "    # plot the stacked bar tot product/ station\n",
    "    my_plot = dwb_df[[\"Station\", \"Failed\", \"Passed\"]].plot(kind=\"bar\", stacked=True, x=\"Station\",\n",
    "        title=\"Fig:3 - Products by station\", figsize=(13,6), fontsize=12)\n",
    "    my_plot.set_xlabel(\"Stations\")\n",
    "    my_plot.set_ylabel(\"Record Count\")\n",
    "    \n",
    "    # plot error rate per station\n",
    "    my_plot = dwb_df[[\"Station\", \"Error\"]].plot(\n",
    "        kind=\"bar\", x=\"Station\",\n",
    "        title=\"Fig:4 - Error by station\", figsize=(13,6), fontsize=12)\n",
    "    my_plot.set_xlabel(\"Stations\")\n",
    "    my_plot.set_ylabel(\"Error %\")\n",
    "    \n",
    "    # process the ppbs result to see how many products has been process by each station.\n",
    "    ppbs_df = pd.DataFrame(\n",
    "        ppbs_result, columns=['Station', 'Processed']).sort(columns=['Station'])\n",
    "    # calculate the missed product for each station: all count - processed count\n",
    "    ppbs_df[\"Missed\"] = ppbs_df[\"Processed\"].apply(lambda x: rows - x)\n",
    "    # the plot\n",
    "    ppbs_df.plot(x=\"Station\", kind=\"bar\", stacked=True,\n",
    "            title=\"Fig: 5 - Products processed by each station\",\n",
    "            figsize=(13,6), fontsize=12)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explore_product_by_station(\"train_numeric\",300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Categorial Data Exploration Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lf, sf = explore_features(\"train_categorical\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this function is to explore sparsity rate per row\n",
    "def explore_sparse_rate(data_set_name, read_rows):\n",
    "    train_categorical = pd.read_csv(INPUT_PATH % data_set_name,nrows = read_rows).drop([\"Id\"], axis=1)\n",
    "    sparse_rate_each_part = []\n",
    "    sparse_rate_series = train_categorical.isnull().sum(axis = 1)/train_categorical.shape[1]\n",
    "    sparse_rate_df = pd.DataFrame(\n",
    "        sparse_rate_series, columns=['sparse_rate'])\n",
    "    return sparse_rate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "explore_sparse_rate('train_categorical', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function is to get feeling of the TX value in the dataset\n",
    "def explore_dintinct_Tx_value(data_set_name, read_rows):\n",
    "    train_categorical = pd.read_csv(INPUT_PATH % 'train_categorical',nrows = read_rows)\n",
    "    del train_categorical['Id']\n",
    "    train_categorical_zeroes = train_categorical.fillna(0)\n",
    "    train_categorical_zeroes = train_categorical_zeroes.values \n",
    "    return np.unique(train_categorical_zeroes[train_categorical_zeroes!=0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "explore_dintinct_Tx_value('train_categorical', 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Enginnering Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Method 1 : Applying PCA for Dimension Reduction\n",
    "Preliminary work to search for appropriate n component\n",
    "benchmark: how many variance is explained or we maintain how much variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import additional pakage\n",
    "import math\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn import preprocessing\n",
    "# define chunksize how many rows load one time\n",
    "chunksize  = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Getting the column headers from first rows\n",
    "# Reading as float32 to save Memory \n",
    "data = pd.read_csv(INPUT_PATH % 'train_numeric',nrows=1)\n",
    "float_cols = [c for c in data]\n",
    "float32_cols = {c: np.float32 for c in float_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the number of pc for preliminary decomposition\n",
    "n_components = 968\n",
    "predictors = [x for x in data.keys() if (x != 'Response' and x != 'Id')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standard_feature_scaling(df):\n",
    "    std_scale = preprocessing.StandardScaler().fit(df)\n",
    "    df_std = pd.DataFrame(std_scale.transform(df))\n",
    "    df_std.columns = df.columns\n",
    "    df_std.index = df.index\n",
    "    return df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mean_imputer(DF):\n",
    "    fill_NaN = preprocessing.Imputer(missing_values=np.nan, strategy='mean')\n",
    "    imputed_DF = pd.DataFrame(fill_NaN.fit_transform(DF))\n",
    "    imputed_DF.columns = DF.columns\n",
    "    imputed_DF.index = DF.index\n",
    "    return imputed_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ipca = IncrementalPCA(n_components=968)\n",
    "# Due to the large dataset read data seperately in chunks and perform IncrementalPCA \n",
    "counter = 0\n",
    "for chunk in pd.read_csv(INPUT_PATH % 'train_numeric', chunksize=chunksize,dtype=float32_cols):\n",
    "    counter += chunksize\n",
    "    print ('processed',counter,'samples')\n",
    "# To do: what value to fill NA \n",
    "    imputed_chunk = chunk[predictors].fillna(0.09)\n",
    "    #imputed_chunk = mean_imputer(chunk[predictors])\n",
    "    scailed_chunk = standard_feature_scaling(imputed_chunk)\n",
    "#    chunk  = scailed_chunk.fillna(0)\n",
    "    ipca.partial_fit(scailed_chunk)\n",
    "print ('Number of Samples Seen:',ipca.n_samples_seen_ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_explained_variance(pca_components):\n",
    "    #print ('Explained variance by %d PCs:' %pca_components, np.sum(ipca.explained_variance_ratio_[:pca_components]))\n",
    "    return np.sum(ipca.explained_variance_ratio_[:pca_components])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot how many variance is explained based on how many n_components\n",
    "n_components_value = range(968)\n",
    "n_components_explained_variance = [get_explained_variance(x) for x in n_components_value]\n",
    "explained_variance_pd = pd.DataFrame(n_components_explained_variance, columns=['explained_variance_rate'])\n",
    "my_plot = explained_variance_pd.plot(title=\"explained_variance_rate\", figsize=(10,6), fontsize=12)\n",
    "my_plot.set_ylabel(\"Explained Variance Rate\")\n",
    "my_plot.set_xlabel(\"Number of Component\")\n",
    "n_components_explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make Train DataFrame only with n PC \n",
    "PC_n = ['f'+str(x) for x in range(0,n_components)]\n",
    "date_final = pd.DataFrame(columns=PC_n)\n",
    "for cat in pd.read_csv(INPUT_PATH % 'train_numeric', chunksize=chunksize,dtype=float32_cols):\n",
    "        cat  = cat.fillna(999)\n",
    "        y=ipca.transform(cat[predictors])\n",
    "        temp = cat['Id'].to_frame()\n",
    "        for i in PC_n:\n",
    "            temp[i]=0\n",
    "        temp[PC_n]=y\n",
    "        date_final = date_final.merge(temp, how='outer')\n",
    "print (date_final)\n",
    "date_final['Id'] = date_final['Id'].astype(np.int32)\n",
    "# save new dataset to CSV file \n",
    "train_filename = 'train_numeric_SVD_%s.csv' % n_components\n",
    "#date_final.to_csv(INPUT_PATH % train_filename,index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make Test DataFrame only with n PC \n",
    "PC_n = ['f'+str(x) for x in range(0,n_components)]\n",
    "date_final = pd.DataFrame(columns=PC_n)\n",
    "for cat in pd.read_csv('../input/test_numeric.csv', chunksize=chunksize,dtype=float32_cols):\n",
    "        cat  = cat.fillna(999)\n",
    "        y=ipca.transform(cat[predictors])\n",
    "        temp = cat['Id'].to_frame()\n",
    "        for i in PC_n:\n",
    "            temp[i]=0\n",
    "        temp[PC_n]=y\n",
    "        date_final = date_final.merge(temp, how='outer')\n",
    "date_final['Id'] = date_final['Id'].astype(np.int32)\n",
    "test_filename = 'test_numeric_SVD_%s.csv' % n_components\n",
    "# Save dataset to CSV file\n",
    "#date_final.to_csv(INPUT_PATH % test_filename,index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2 : XGBoost to select important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import additional package\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import matthews_corrcoef, roc_auc_score\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample the data in a roundabout way to get : \n",
    "date_chunks = pd.read_csv(\"../data/train_date.csv\", index_col=0, chunksize=10000, dtype=np.float32)\n",
    "num_chunks = pd.read_csv(\"../data/train_numeric.csv\", index_col=0,\n",
    "                         usecols=list(range(969)), chunksize=10000, dtype=np.float32)\n",
    "df_train = pd.concat([pd.concat([dchunk, nchunk], axis=1).sample(frac=0.05)\n",
    "               for dchunk, nchunk in zip(date_chunks, num_chunks)])\n",
    "y_sample = pd.read_csv(\"../data/train_numeric.csv\", index_col=0, usecols=[0,969], dtype=np.float32).loc[X.index].values.ravel()\n",
    "x_sample = df_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = XGBClassifier(base_score=0.005)\n",
    "clf.fit(x_sample, y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fea_importance = pd.DataFrame(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# threshold for a manageable number of features\n",
    "plt.hist(clf.feature_importances_[clf.feature_importances_>0])\n",
    "important_indices = np.where(clf.feature_importances_>0.005)[0]\n",
    "print(important_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load entire dataset for these features. \n",
    "# note where the feature indices are split so we can load the correct ones straight from read_csv\n",
    "n_date_features = 1156\n",
    "X = np.concatenate([\n",
    "    pd.read_csv(\"../data/train_date.csv\", index_col=0, dtype=np.float32,\n",
    "                usecols=np.concatenate([[0], important_indices[important_indices < n_date_features] + 1])).values,\n",
    "    pd.read_csv(\"../data/train_numeric.csv\", index_col=0, dtype=np.float32,\n",
    "                usecols=np.concatenate([[0], important_indices[important_indices >= n_date_features] + 1 - 1156])).values\n",
    "], axis=1)\n",
    "y = pd.read_csv(\"../data/train_numeric.csv\", index_col=0, dtype=np.float32, usecols=[0,969]).values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 : XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Hyper-Parameter Tuning Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import additional library\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data nearly same as previous section\n",
    "#TODO: need refractor so that all code is consistent\n",
    "# define Idcol and Response Column\n",
    "IDcol = \"Id\"\n",
    "target = \"Response\"\n",
    "# Sample the data to decide some important features\n",
    "start_time = datetime.datetime.now()\n",
    "date_chunks = pd.read_csv(\"../data/train_date.csv\", index_col=0, chunksize=chunksize, dtype=np.float32)\n",
    "num_chunks = pd.read_csv(\"../data/train_numeric.csv\", index_col=0, chunksize=chunksize, dtype=np.float32)\n",
    "train_value = pd.concat([pd.concat([dchunk, nchunk], axis=1).sample(frac=0.001)\n",
    "               for dchunk, nchunk in zip(date_chunks, num_chunks)])\n",
    "end_time = datetime.datetime.now()\n",
    "print (end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# self-defined xgb model wrapper including data processing, model fit, predict and result \n",
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=20):\n",
    "    # trainCV with early stop so we don't need to use sciki-learn GridsearchCV , the later can't run in my computer\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain[target],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain[target].values, dtrain_predictions))\n",
    "    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain[target], dtrain_predprob))\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in train_value.columns if x not in [target, IDcol]]\n",
    "xgb_starter = XGBClassifier(\n",
    " learning_rate =0.01,\n",
    " n_estimators=2000,\n",
    " max_depth=10,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=1,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27,\n",
    " base_score=0.005)\n",
    "modelfit(xgb_starter, train_value, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Train and prediction part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = XGBClassifier(max_depth=5, base_score=0.005)\n",
    "cv = StratifiedKFold(y, n_folds=3)\n",
    "preds = np.ones(y.shape[0])\n",
    "for i, (train, test) in enumerate(cv):\n",
    "    preds[test] = clf.fit(X[train], y[train]).predict_proba(X[test])[:,1]\n",
    "    print(\"fold {}, ROC AUC: {:.3f}\".format(i, roc_auc_score(y[test], preds[test])))\n",
    "print(roc_auc_score(y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pick the best threshold by MCC\n",
    "thresholds = np.linspace(0.01, 0.99, 50)\n",
    "mcc = np.array([matthews_corrcoef(y, preds>thr) for thr in thresholds])\n",
    "plt.plot(thresholds, mcc)\n",
    "best_threshold = thresholds[mcc.argmax()]\n",
    "print(mcc.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load test data\n",
    "X = np.concatenate([\n",
    "    pd.read_csv(\"../data/test_date.csv\", index_col=0, dtype=np.float32,\n",
    "                usecols=np.concatenate([[0], important_indices[important_indices<1156]+1])).values,\n",
    "    pd.read_csv(\"../data/test_numeric.csv\", index_col=0, dtype=np.float32,\n",
    "                usecols=np.concatenate([[0], important_indices[important_indices>=1156] +1 - 1156])).values\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate predictions at the chosen threshold\n",
    "preds = (clf.predict_proba(X)[:,1] > best_threshold).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# and submit\n",
    "sub = pd.read_csv(\"../data/sample_submission.csv\", index_col=0)\n",
    "sub[\"Response\"] = preds\n",
    "sub.to_csv(\"submission.csv.gz\", compression=\"gzip\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
